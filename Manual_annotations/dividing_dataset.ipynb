{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc2e3eb-254a-4642-84c3-a6120f248de8",
   "metadata": {},
   "source": [
    "# Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0dffa-c96e-4bc9-8e0a-26c624e9f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a65e82-116a-46cd-a778-0af72f2389b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from the  huggingface library\n",
    "\n",
    "splits = {'validation': 'en/validation-00000-of-00001.parquet', 'test': 'en/test-00000-of-00001.parquet', 'train': 'en/train-00000-of-00001.parquet'}\n",
    "train = pd.read_parquet(\"hf://datasets/unimelb-nlp/wikiann/\" + splits[\"train\"])\n",
    "val = pd.read_parquet(\"hf://datasets/unimelb-nlp/wikiann/\" + splits[\"validation\"])\n",
    "test = pd.read_parquet(\"hf://datasets/unimelb-nlp/wikiann/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91f050-0321-4c72-852b-fc99a516062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 2000 rows from the training data\n",
    "\n",
    "subset=train[train.index % 10 == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64616266-df20-40ec-91e6-f6db1a922148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each list of tokens to a readable string\n",
    "\n",
    "sentences=[]\n",
    "for index, row in subset.iterrows():\n",
    "    sent=\" \".join(row['tokens'])\n",
    "    sent=\"# New sentence = \"+sent\n",
    "    sentences.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf511f-33dc-4ac0-972a-7a0deb96d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the sentence strings before each list of strings row in the dataframe\n",
    "\n",
    "expanded=subset.copy()\n",
    "for i, sentence in reversed(list(enumerate(sentences))):\n",
    "    line=pd.DataFrame({'tokens':sentence, 'ner_tags':[0], 'langs':['en'], 'spans':['']})\n",
    "    expanded=pd.concat([expanded.iloc[:i], line, expanded.iloc[i:]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a91e9-7c5f-4218-be02-b5ccf87c93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens=expanded.explode('tokens')\n",
    "toks=all_tokens['tokens']\n",
    "# toks.to_csv('gathered_results.csv', index=False, encoding='UTF-8', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a95a92-2169-432b-a2cd-4888a601fd78",
   "metadata": {},
   "source": [
    "# Dividing it between us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d10838-198e-4d7c-9ca7-dd5941564191",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=expanded[0:1000]\n",
    "B=expanded[1000:2000]\n",
    "C=expanded[2000:3000]\n",
    "D=expanded[3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65ffaa-e811-41d5-9587-619fc40333d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Am=pd.concat([A, D])\n",
    "Amina=Am.explode('tokens')\n",
    "Amina['labels']=0\n",
    "Amina=Amina[['tokens', 'labels']]\n",
    "# Amina.to_csv('Amina_annotations.csv', index=False, encoding='UTF-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3b632-280f-450f-a573-cf2502735c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Li=pd.concat([A,B])\n",
    "Lilja=Li.explode('tokens')\n",
    "Lilja['labels']=0\n",
    "Lilja=Lilja[['tokens', 'labels']]\n",
    "# Lilja.to_csv('Lilja_annotations.csv', index=False, encoding='UTF-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bada65-d1d8-4fbc-947b-4fd37d676140",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mi=pd.concat([B,C])\n",
    "Miko=Mi.explode('tokens')\n",
    "Miko['labels']=0\n",
    "Miko=Miko[['tokens', 'labels']]\n",
    "# Miko.to_csv('Mikolaj_annotations.csv', index=False, encoding='UTF-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a5a14-5fa5-4fb5-92f5-44c59b2647f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zo=pd.concat([C,D])\n",
    "Zosia=Zo.explode('tokens')\n",
    "Zosia['labels']=0\n",
    "Zosia=Zosia[['tokens', 'labels']]\n",
    "# Zosia.to_csv('Zosia_annotations.csv', index=False, encoding='UTF-8', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ce8df-e7c9-4276-a376-f5811124241e",
   "metadata": {},
   "source": [
    "# Reading the results back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f6a25-3d0e-4657-b800-f91d004b1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.read_csv('results.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d154ff-b8a5-49ce-9a7b-761605fbdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=results.fillna('0')\n",
    "results['labels1']=results['labels1'].astype(int)\n",
    "results['labels2']=results['labels2'].astype(int)\n",
    "results['labels1']=results['labels1'].astype(str)\n",
    "results['labels2']=results['labels2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454458a-f072-4cb6-9b9d-33e255cf408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=''\n",
    "YAY=0\n",
    "FALSEPOSNEG=0\n",
    "ORGLOCERR=0\n",
    "LOCSPLITERR=0\n",
    "locspliterrlist=[]\n",
    "OTHERERR=0\n",
    "weird_results=[]\n",
    "annotator1_results=[]\n",
    "annotator2_results=[]\n",
    "\n",
    "location=False\n",
    "for index, row in results.iterrows():\n",
    "    \n",
    "    token=row.iloc[0]\n",
    "    label1=row.iloc[1]\n",
    "    label2=row.iloc[2]\n",
    "    \n",
    "    if token[0]=='#':\n",
    "        sentence=token[17:]\n",
    "        continue\n",
    "    labels1.append(label1)\n",
    "    labels2.append(label2)\n",
    "    \n",
    "    if label1 == label2:\n",
    "        YAY +=1\n",
    "        \n",
    "    else:\n",
    "        if ( ( label1 in ['3','4'] ) and (label2 in ['5','6'] ) ) or ( ( label2 in ['3','4'] ) and (label1 in ['5','6'] ) ):\n",
    "            ORGLOCERR+=1\n",
    "\n",
    "        elif label1=='5' or label2=='5':\n",
    "            location=True\n",
    "            if label1=='0' or label2=='0':\n",
    "                FALSEPOSNEG+=1\n",
    "                continue\n",
    "                \n",
    "        elif ( label1=='0' and label2 in ['5','6'] ) or ( label2=='0' and label1 in ['5','6'] ) or (label1 in ['5', '6'] and label2 in ['5', '6']):\n",
    "            LOCSPLITERR+=1\n",
    "            locspliterrlist.append((sentence, token, label1, label2))\n",
    "\n",
    "        elif label1=='0' or label2=='0':\n",
    "            FALSEPOSNEG+=1\n",
    "        else:\n",
    "            OTHERERR+=1\n",
    "            weird_results.append((sentence, token, label1, label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7303e450-f410-4303-bc16-fc39e7a654c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correct results: \", YAY)\n",
    "print(\"False positives or negatives: \", FALSEPOSNEG)\n",
    "print(\"Disagreements of organisation or location: \", ORGLOCERR)\n",
    "print(\"Location-splitting error (or perhaps just false negatives): \", LOCSPLITERR)\n",
    "print(\"Nr of other unidentified errors: \", OTHERERR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7368b0a",
   "metadata": {},
   "source": [
    "# Accuracy and Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb1f796-07ef-469d-a47d-910fdd188314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy between two lists of labels\n",
    "def calculate_accuracy(labels1, labels2):\n",
    "    total_tokens = len(labels1)\n",
    "    correct_tokens = sum(1 for label1, label2 in zip(labels1, labels2) if label1 == label2)\n",
    "    accuracy = correct_tokens / total_tokens\n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy(results['labels1'], results['labels2'])\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960816a1-18a6-4324-be29-7f19f8d4c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def cohen_kappa(annotation1, annotation2):\n",
    "    #how much of each annotation\n",
    "    count1 = Counter(annotation1)\n",
    "    count2 = Counter(annotation2)\n",
    "    \n",
    "    # Observed agreement (P_o)\n",
    "    observed_agreement = sum((a == b) for a, b in zip(annotation1, annotation2)) / len(annotation1)\n",
    "    \n",
    "    # Expected agreement (P_e)\n",
    "    total = len(annotation1)\n",
    "    categories = set(annotation1).union(set(annotation2)) # categories that appear in either of annotations\n",
    "    expected_agreement = 0\n",
    "    \n",
    "    for category in categories:\n",
    "        p1 = count1.get(category, 0) / total\n",
    "        p2 = count2.get(category, 0) / total\n",
    "        expected_agreement += p1 * p2\n",
    "    \n",
    "    # Cohen's Kappa calculation\n",
    "    kappa = (observed_agreement - expected_agreement) / (1 - expected_agreement) #from the formula\n",
    "    return kappa\n",
    "\n",
    "# Calculate Cohen's Kappa\n",
    "kappa = cohen_kappa(results['labels1'], results['labels2'])\n",
    "print(f\"Cohen's Kappa: {kappa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8773c600-7c81-4060-ad01-04c6e7a0335d",
   "metadata": {},
   "source": [
    "# F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d451a3-0fd6-4408-bbb1-ef36964f4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "silver = silver_data_list\n",
    "gold_a = annotator1_results\n",
    "gold_b = annotator2_results\n",
    "\n",
    "y_true_relaxed = []\n",
    "y_pred_relaxed = []\n",
    "\n",
    "for i, pred in enumerate(silver):\n",
    "    if pred == gold_a[i] or pred == gold_b[i]:\n",
    "        y_true_relaxed.append(pred)  # it's a match, count it as correct\n",
    "        y_pred_relaxed.append(pred)\n",
    "    else:\n",
    "        y_true_relaxed.append(gold_a[i])  # mark mismatch with one of the annotators\n",
    "        y_pred_relaxed.append(pred)\n",
    "\n",
    "print(\"Macro F1:\", f1_score(y_true_relaxed, y_pred_relaxed, average='macro'))\n",
    "print(\"Micro F1:\", f1_score(y_true_relaxed, y_pred_relaxed, average='micro'))\n",
    "print(\"Weighted F1:\", f1_score(y_true_relaxed, y_pred_relaxed, average='weighted'))\n",
    "print(\"Per-class F1:\", f1_score(y_true_relaxed, y_pred_relaxed, average=None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd9896b-87f5-4256-b6eb-eefc12470247",
   "metadata": {},
   "source": [
    "# Compare to silver data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4faeba-8a51-4296-b74c-e72ebc38b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_data=subset[['tokens', 'ner_tags']]\n",
    "silver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d515f1-cc11-4541-9d67-0babf8321d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_data_list=[]\n",
    "for index, row in silver_data.iterrows():\n",
    "    tokens=row.iloc[0]\n",
    "    tags=row.iloc[1]\n",
    "    for token, tag in zip(tokens, tags):\n",
    "        print(token, tag)\n",
    "        silver_data_list.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3409136-c193-4d49-af46-206c487bd019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285f402-e666-40c6-84f8-d83fd06962c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

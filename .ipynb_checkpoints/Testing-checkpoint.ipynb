{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f5b505-a2a8-45ea-9121-f5b19101f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44da5e1a-aa74-484b-8088-c5f7325c85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ewt_file(path):\n",
    "    data=[]\n",
    "    words=[]\n",
    "    tags=[]\n",
    "    nr_tags=0\n",
    "    nr_toks=0\n",
    "    \n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        line=line.strip()\n",
    "        \n",
    "        if line:\n",
    "            if line[0]=='#':\n",
    "                continue\n",
    "    \n",
    "            elements=line.split('\\t')\n",
    "            nr_toks+=1\n",
    "            \n",
    "            words.append(elements[1])\n",
    "            tags.append(elements[2])\n",
    "            \n",
    "            if elements[3]!='-':\n",
    "                print(elements[3])\n",
    "            if elements[4]=='stephen':\n",
    "                nr_tags+=1\n",
    "    \n",
    "        else:\n",
    "            if words:\n",
    "                data.append((words, tags))\n",
    "            words=[]\n",
    "            tags=[]\n",
    "\n",
    "    if tags!=[]:\n",
    "        data.append((words, tags))\n",
    "\n",
    "    proportion_tagged=nr_tags/nr_toks\n",
    "    \n",
    "    return data, proportion_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d416d0a-756f-4252-bc9c-3cd89d382966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of training data tagged:  0.050640583833140254\n",
      "Proportion of testing data tagged:  0.05948546661895105\n"
     ]
    }
   ],
   "source": [
    "train_data,prop_tag_train=read_ewt_file('Project_description/en_ewt-ud-train.iob2')\n",
    "test_data,prop_tag_test=read_ewt_file('Project_description/en_ewt-ud-dev.iob2')\n",
    "print(\"Proportion of training data tagged: \", prop_tag_train)\n",
    "print(\"Proportion of testing data tagged: \", prop_tag_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e1ebca8-5dac-4e36-9b82-0899e9ca9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab=['<PAD>']\n",
    "class_vocab=['<PAD>']\n",
    "for pair in train_data:\n",
    "    for word, clas in zip(pair[0], pair[1]):\n",
    "        if word not in word_vocab:\n",
    "            word_vocab.append(word)\n",
    "        if clas not in class_vocab:\n",
    "            class_vocab.append(clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d89d0823-35c0-418a-885a-97bb38155e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_diff_words=len(word_vocab)\n",
    "nr_sent=len(train_data)\n",
    "longest_sent=max([len(x[0]) for x in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b1b5515-477c-4915-87db-7f246bb9979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_matrix=torch.zeros((nr_sent,longest_sent)) #PyTorch tensor of dim 12543 x 159 . Should consist of sentences word by word as rows, and padding for shorter sentences.\n",
    "train_label_matrix=torch.zeros((nr_sent,longest_sent)) #PyTorch tensor of dim 12543 x 159, containing values from the label index for each word in the train_data_matrix\n",
    "\n",
    "#I'll start by just making sure that a matrix of words and padding works for the training data, then do it as indices in a vocabulary next.\n",
    "\n",
    "for sent_nr, (sentence, classes) in enumerate(train_data):\n",
    "    for tok_nr, (token, clas) in enumerate(zip(sentence, classes)):\n",
    "        token_idx=word_vocab.index(token)\n",
    "        clas_idx=class_vocab.index(clas)\n",
    "        train_data_matrix[sent_nr,tok_nr]=round(token_idx)\n",
    "        train_label_matrix[sent_nr,tok_nr]=round(clas_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58c2a759-d9dc-4dd2-9daa-51f8d1f8d5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "num_batches=int(len(train_data_matrix)/batch_size)\n",
    "print(num_batches)\n",
    "\n",
    "feats_batches=train_data_matrix[:batch_size*num_batches].view(num_batches, batch_size, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a88cd-625c-4c51-8269-f63d09e7992a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e34c03-da2d-4697-a14b-4bea724689ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
